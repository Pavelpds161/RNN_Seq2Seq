{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2Seq_encoder-decoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRT_4fzVVOsQ",
        "colab_type": "text"
      },
      "source": [
        "### Implementation of the model Seq2Seq\n",
        "\n",
        "#### Encoder-Decoder (without attention)\n",
        "\n",
        "##### Task: train a chatbot (base) on a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMnq-IQdUYef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using TensorFlow 2.0\n",
        "# Switching to version 2.0 (only works in Colab)\n",
        "\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ew7HTbPpCJH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "547e83a2-af49-4fdf-c96b-bc6ae99a0d54"
      },
      "source": [
        "# Loading libraries\n",
        "# TensorFlow must have at least version 2.0\n",
        "\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQbFLFByveO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading and reading data\n",
        "# We will use dialogues from movies as a training dataset\n",
        "\n",
        "# connecting to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPdx_2aWvfBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08f9430d-5dca-40cc-9836-4b3379aefa9b"
      },
      "source": [
        "# working directory; create a directory at the first launch (if it doesn't exist yet),\n",
        "# otherwise, replace True with False\n",
        "if False:\n",
        "    !mkdir \"/content/drive/My Drive/Seq2Seq_light\"\n",
        "%cd \"/content/drive/My Drive/Seq2Seq_light\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Seq2Seq_light\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWuqWpkBwYhI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "7133aee6-5ed3-49ee-bb8c-f43cf54ef533"
      },
      "source": [
        "# uploading data (ChatBot_Dataset) to the current working directory (Seq2Seq_light)\n",
        "if False:\n",
        "    !7z x ChatBot_Dataset.7z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 6741321 bytes (6584 KiB)\n",
            "\n",
            "Extracting archive: ChatBot_Dataset.7z\n",
            "--\n",
            "Path = ChatBot_Dataset.7z\n",
            "Type = 7z\n",
            "Physical Size = 6741321\n",
            "Headers Size = 237\n",
            "Method = LZMA2:25\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 40% 2 - ChatBot_Dataset/movie_lines.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 2 - ChatBot_Dataset/movie_lines.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 1\n",
            "Files: 2\n",
            "Size:       41402849\n",
            "Compressed: 6741321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK1BHST4vfHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "76a9371e-80b9-408a-e21d-e951777cc992"
      },
      "source": [
        "# let's look at the contents of the files\n",
        "movie_convers = open('ChatBot_Dataset/movie_conversations.txt',mode='rt')\n",
        "movie_convers = movie_convers.readlines()\n",
        "movie_convers[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\\n\",\n",
              " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\\n\",\n",
              " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw6FtcTb02C-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "74bfeaf3-f410-4aae-b3c1-b3cbc4762dba"
      },
      "source": [
        "# let's look at the contents of the files\n",
        "with codecs.open('ChatBot_Dataset/movie_lines.txt', encoding='cp1251', errors='ignore') as file:\n",
        "    movie_lines = [movie_lines for movie_lines in file]\n",
        "\n",
        "movie_lines[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n',\n",
              " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n',\n",
              " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3jCe2I2002D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "9736bec0-de40-4cdc-f922-3dca6f491ff7"
      },
      "source": [
        "# Data pre-processing\n",
        "# converting our list data to dataframe (movie_convers)\n",
        "\n",
        "character_id_1 = []\n",
        "character_id_2 = []\n",
        "movie_id = []\n",
        "dialogues = []\n",
        "\n",
        "for line in movie_convers: \n",
        "    line_row = line.split('+++$+++')\n",
        "    character_id_1.append(line_row[0].strip())\n",
        "    character_id_2.append(line_row[1].strip())\n",
        "    movie_id.append(line_row[2].strip())\n",
        "    dialogues.append(line_row[3].strip())\n",
        "\n",
        "movie_convers_df = pd.DataFrame({'character_id_1': character_id_1, \n",
        "                                 'character_id_2': character_id_2, \n",
        "                                 'movie_id': movie_id, \n",
        "                                 'dialogues': dialogues}, \n",
        "                                columns = ['character_id_1', \n",
        "                                           'character_id_2', \n",
        "                                           'movie_id', \n",
        "                                           'dialogues']) \n",
        "\n",
        "print(movie_convers_df.shape)\n",
        "movie_convers_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(83097, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>character_id_1</th>\n",
              "      <th>character_id_2</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>dialogues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L194', 'L195', 'L196', 'L197']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L198', 'L199']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L200', 'L201', 'L202', 'L203']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L204', 'L205', 'L206']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L207', 'L208']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  character_id_1 character_id_2 movie_id                         dialogues\n",
              "0             u0             u2       m0  ['L194', 'L195', 'L196', 'L197']\n",
              "1             u0             u2       m0                  ['L198', 'L199']\n",
              "2             u0             u2       m0  ['L200', 'L201', 'L202', 'L203']\n",
              "3             u0             u2       m0          ['L204', 'L205', 'L206']\n",
              "4             u0             u2       m0                  ['L207', 'L208']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO4OELmKyirH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "24b9a1d6-1584-4227-98fb-c188cd5abd6e"
      },
      "source": [
        "# converting our list data to dataframe (movie_lines)\n",
        "\n",
        "line_id = []\n",
        "character_id = []\n",
        "movie_id = []\n",
        "name = []\n",
        "text = []\n",
        "\n",
        "for line in movie_lines: \n",
        "    line = line.replace('\\t', '')\n",
        "    line = line.replace('\\xad', '')\n",
        "    line_row = line.split('+++$+++')\n",
        "    line_id.append(line_row[0].strip())\n",
        "    character_id.append(line_row[1].strip())\n",
        "    movie_id.append(line_row[2].strip())\n",
        "    name.append(line_row[3].strip())\n",
        "    text.append(line_row[4].strip())\n",
        "\n",
        "movie_lines_df = pd.DataFrame({'line_id': line_id, \n",
        "                               'character_id': character_id, \n",
        "                               'movie_id': movie_id, \n",
        "                               'name': name, \n",
        "                               'text': text}, \n",
        "                                columns = ['line_id', \n",
        "                                           'character_id', \n",
        "                                           'movie_id', \n",
        "                                           'name', \n",
        "                                           'text']) \n",
        "\n",
        "print(movie_lines_df.shape)\n",
        "movie_lines_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(304713, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>line_id</th>\n",
              "      <th>character_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1045</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>They do not!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1044</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>They do to!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L985</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>I hope so.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L984</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>She okay?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L925</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>Let's go.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  line_id character_id movie_id     name          text\n",
              "0   L1045           u0       m0   BIANCA  They do not!\n",
              "1   L1044           u2       m0  CAMERON   They do to!\n",
              "2    L985           u0       m0   BIANCA    I hope so.\n",
              "3    L984           u2       m0  CAMERON     She okay?\n",
              "4    L925           u0       m0   BIANCA     Let's go."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "salCs9G9Zqq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input (input_texts) and output offers (target_texts)\n",
        "movie_array = movie_lines_df.iloc[:, 4:5].to_numpy()[:10000]\n",
        "input_texts = movie_array[:-1]\n",
        "target_texts = movie_array[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdTllVeCrQuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dictionaries\n",
        "def prepare_vocab(texts):\n",
        "    vocab = sorted(set(' '.join(map(str, texts))))\n",
        "    vocab.append('<START>')\n",
        "    vocab.append('<END>')\n",
        "    vocab_size = len(vocab)\n",
        "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "    idx2char = np.array(vocab)\n",
        "    return vocab_size, char2idx, idx2char\n",
        "\n",
        "INPUT_VOCAB_SIZE, input_char2idx, input_idx2char = prepare_vocab(input_texts)\n",
        "TARGET_VOCAB_SIZE, target_char2idx, target_idx2char = prepare_vocab(target_texts)\n",
        "\n",
        "# arrays of lists to arrays of strings\n",
        "input_texts = np.resize(input_texts, (input_texts.shape[0], ))\n",
        "target_texts = np.resize(target_texts, (target_texts.shape[0], ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2sM-GTGRVoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder_input_seqs-inputs to the Encoder\n",
        "# decoder_input_seqs-inputs in the Decoder\n",
        "# decoder_target_seqs-target outputs from Decoder (and the entire Encoder-Decoder model)\n",
        "# chains will be sequences of integer indexes\n",
        "\n",
        "input_texts_as_int = [[input_char2idx[c] for c in text] for text in input_texts]\n",
        "target_texts_as_int = [[target_char2idx[c] for c in text] for text in target_texts]\n",
        "\n",
        "encoder_input_seqs = [np.array(text) for text in input_texts_as_int]\n",
        "decoder_input_seqs = []\n",
        "decoder_target_seqs = []\n",
        "for target_text in target_texts_as_int:\n",
        "    decoder_input_seqs.append(np.array([target_char2idx['<START>']] + target_text))\n",
        "    decoder_target_seqs.append(np.array(target_text + [target_char2idx['<END>']]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ4uB2IsRV2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e8b47464-14cf-47a2-a34a-508fca92ffc2"
      },
      "source": [
        "# padding of chains\n",
        "# before making padding, let's look at the chains\n",
        "\n",
        "print(encoder_input_seqs[:3])\n",
        "print('-----------------')\n",
        "print(decoder_input_seqs[:3])\n",
        "print('-----------------')\n",
        "print(decoder_target_seqs[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([47, 65, 62, 82,  0, 61, 72,  0, 71, 72, 77,  1]), array([47, 65, 62, 82,  0, 61, 72,  0, 77, 72,  1]), array([36,  0, 65, 72, 73, 62,  0, 76, 72, 11])]\n",
            "-----------------\n",
            "[array([87, 47, 65, 62, 82,  0, 61, 72,  0, 77, 72,  1]), array([87, 36,  0, 65, 72, 73, 62,  0, 76, 72, 11]), array([87, 46, 65, 62,  0, 72, 68, 58, 82, 27])]\n",
            "-----------------\n",
            "[array([47, 65, 62, 82,  0, 61, 72,  0, 77, 72,  1, 88]), array([36,  0, 65, 72, 73, 62,  0, 76, 72, 11, 88]), array([46, 65, 62,  0, 72, 68, 58, 82, 27, 88])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI1-jMO4VEIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_enc_seq_length = max([len(seq) for seq in encoder_input_seqs])\n",
        "max_dec_seq_length = max([len(seq) for seq in decoder_input_seqs])\n",
        "\n",
        "encoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    encoder_input_seqs,\n",
        "    value=input_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_enc_seq_length)\n",
        "\n",
        "decoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    decoder_input_seqs,\n",
        "    value=target_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_dec_seq_length)\n",
        "\n",
        "decoder_target_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    decoder_target_seqs,\n",
        "    value=target_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_dec_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAs1SJ9FlLvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a model\n",
        "\n",
        "H_SIZE = 256 # Dimension of the hidden state\n",
        "EMB_SIZE = 256 # embedding dimension (for both input and output chains)\n",
        "BATCH_SIZE = 64\n",
        "#INPUT_VOCAB_SIZE\n",
        "#TARGET_VOCAB_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0IH4q_bwVLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm0 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, \n",
        "                                                                        return_sequences=True, \n",
        "                                                                        return_state=True)) \n",
        "        self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, \n",
        "                                                                        return_sequences=False, \n",
        "                                                                        return_state=True))\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embed(x)\n",
        "        out, h0_f, c0_f, h0_b, c0_b = self.lstm0(out)\n",
        "        out, h1_f, c1_f, h1_b, c1_b = self.lstm1(out)\n",
        "        h0 = tf.keras.layers.Concatenate()([h0_f, h0_b])\n",
        "        c0 = tf.keras.layers.Concatenate()([c0_f, c0_b])\n",
        "        h1 = tf.keras.layers.Concatenate()([h1_f, h1_b])\n",
        "        c1 = tf.keras.layers.Concatenate()([c1_f, c1_b])\n",
        "        state = [(h0, c0), (h1, c1)]\n",
        "        return state\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm0 = tf.keras.layers.LSTM(H_SIZE*2, \n",
        "                                          return_sequences=True, \n",
        "                                          return_state=True)\n",
        "        self.lstm1 = tf.keras.layers.LSTM(H_SIZE*2, \n",
        "                                          return_sequences=True, \n",
        "                                          return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "    def call(self, x, init_state):\n",
        "        out = self.embed(x)\n",
        "        out, h0, c0 = self.lstm0(out, initial_state=init_state[0])\n",
        "        out, h1, c1 = self.lstm1(out, initial_state=init_state[1])\n",
        "\n",
        "        out = self.fc(out)\n",
        "        state = [(h0, c0), (h1, c1)]\n",
        "        return out, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXaAKs5p6qcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "6c98a835-d33c-4491-879e-e737099f52be"
      },
      "source": [
        "encoder_model = Encoder()\n",
        "decoder_model = Decoder()\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "enc_state = encoder_model(encoder_inputs)\n",
        "decoder_outputs, _ = decoder_model(decoder_inputs, enc_state)\n",
        "\n",
        "# general model\n",
        "seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "seq2seq.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1 (Encoder)             [((None, 512), (None 2648320     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_1 (Decoder)             ((None, None, 89), [ 3742553     input_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,390,873\n",
            "Trainable params: 6,390,873\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZL0Jc6-QPYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training model \n",
        "\n",
        "EPOCHS = 50\n",
        "loss = tf.losses.SparseCategoricalCrossentropy()\n",
        "seq2seq.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEWXAYQgz6lz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "3cf3f55a-bbfe-494a-bcdf-25547c86216a"
      },
      "source": [
        "seq2seq.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs, \n",
        "            batch_size=BATCH_SIZE, \n",
        "            epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0513 - accuracy: 0.9843\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0502 - accuracy: 0.9846\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0493 - accuracy: 0.9849\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0482 - accuracy: 0.9852\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0471 - accuracy: 0.9855\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0459 - accuracy: 0.9859\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0448 - accuracy: 0.9862\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0435 - accuracy: 0.9866\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0423 - accuracy: 0.9870\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 173s 1s/step - loss: 0.0408 - accuracy: 0.9875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0479b6dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2RPBlHDz_66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for inference  \n",
        "\n",
        "def seq2seq_inference(input_seq):\n",
        "    state = encoder_model(input_seq)\n",
        "\n",
        "    target_seq = np.array([[target_char2idx['<START>']]])\n",
        "\n",
        "    decoded_sentence = ''\n",
        "    while True:\n",
        "        output_tokens, state = decoder_model(target_seq, state)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = target_idx2char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '<END>' or\n",
        "           len(decoded_sentence) > max_dec_seq_length):\n",
        "            break\n",
        "\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T_mlc2i0HQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "d901a4c2-ebdb-492c-de7d-490ece27cbd3"
      },
      "source": [
        "# Example of inference \n",
        "\n",
        "for seq_index in range(70, 80):\n",
        "    input_seq = encoder_input_seqs[seq_index: seq_index + 1]\n",
        "    decoded_sentence = seq2seq_inference(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Result sentence:', decoded_sentence)\n",
        "    print('Target sentence:', target_texts[seq_index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: You think you ' re the only sophomore at the prom?\n",
            "Result sentence: I don't know.  I'm not at all.<END>\n",
            "Target sentence: I don't have to be home 'til two.\n",
            "-\n",
            "Input sentence: I don't have to be home 'til two.\n",
            "Result sentence: What are you doing to say?<END>\n",
            "Target sentence: I have to be home in twenty minutes.\n",
            "-\n",
            "Input sentence: I have to be home in twenty minutes.\n",
            "Result sentence: What are you doing?<END>\n",
            "Target sentence: All I know is -- I'd give up my private line to go out with a guy like Joey.\n",
            "-\n",
            "Input sentence: All I know is -- I'd give up my private line to go out with a guy like Joey.\n",
            "Result sentence: I don't know what you did.<END>\n",
            "Target sentence: Sometimes I wonder if the guys we're supposed to want to go out with are the ones we actually want to go out with, you know?\n",
            "-\n",
            "Input sentence: Sometimes I wonder if the guys we're supposed to want to go out with are the ones we actually want to go out with, you know?\n",
            "Result sentence: What are you doing?<END>\n",
            "Target sentence: Bianca, I don't think the highlights of dating Joey Dorsey are going to include door-opening and coat-holding.\n",
            "-\n",
            "Input sentence: Bianca, I don't think the highlights of dating Joey Dorsey are going to include door-opening and coat-holding.\n",
            "Result sentence: Who is he?<END>\n",
            "Target sentence: Combination.  I don't know -- I thought he'd be different.  More of a gentleman...\n",
            "-\n",
            "Input sentence: Combination.  I don't know -- I thought he'd be different.  More of a gentleman...\n",
            "Result sentence: What do you think?<END>\n",
            "Target sentence: Is he oily or dry?\n",
            "-\n",
            "Input sentence: Is he oily or dry?\n",
            "Result sentence: What are you doing?<END>\n",
            "Target sentence: He practically proposed when he found out we had the same dermatologist. I mean. Dr. Bonchowski is great an all, but he's not exactly relevant party conversation.\n",
            "-\n",
            "Input sentence: He practically proposed when he found out we had the same dermatologist. I mean. Dr. Bonchowski is great an all, but he's not exactly relevant party conversation.\n",
            "Result sentence: It's not the bank.<END>\n",
            "Target sentence: Would you mind getting me a drink, Cameron?\n",
            "-\n",
            "Input sentence: Would you mind getting me a drink, Cameron?\n",
            "Result sentence: I want to know what you did.<END>\n",
            "Target sentence: Great\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1CUyv-bQQS0",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder-Decoder with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPyDyn24P2Zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm0 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, \n",
        "                                                                        return_sequences=True, \n",
        "                                                                        return_state=True)) \n",
        "        self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, \n",
        "                                                                        return_sequences=True, \n",
        "                                                                        return_state=True))\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embed(x)\n",
        "        out, h0_f, c0_f, h0_b, c0_b = self.lstm0(out)\n",
        "        out, h1_f, c1_f, h1_b, c1_b = self.lstm1(out)\n",
        "        h0 = tf.keras.layers.Concatenate()([h0_f, h0_b])\n",
        "        c0 = tf.keras.layers.Concatenate()([c0_f, c0_b])\n",
        "        h1 = tf.keras.layers.Concatenate()([h1_f, h1_b])\n",
        "        c1 = tf.keras.layers.Concatenate()([c1_f, c1_b])\n",
        "        state = [(h0, c0), (h1, c1)]\n",
        "        return out, state\n",
        "\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.dense1 = tf.keras.layers.Dense(1, \n",
        "                                          input_shape=(1, \n",
        "                                                       encoder_input_seqs.shape[1], \n",
        "                                                       H_SIZE*2), activation=\"softmax\")\n",
        "\n",
        "    def call(self, encoder_out):\n",
        "      x = encoder_out\n",
        "      x = self.dense1(x)\n",
        "      return x\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm0 = tf.keras.layers.LSTM(H_SIZE*2, \n",
        "                                          return_sequences=True, \n",
        "                                          return_state=True)\n",
        "        self.lstm1 = tf.keras.layers.LSTM(H_SIZE*2, \n",
        "                                          return_sequences=True, \n",
        "                                          return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation='softmax')\n",
        "         \n",
        "    def call(self, x, init_state, att_out):\n",
        "        out = self.embed(x)\n",
        "        out, h0, c0 = self.lstm0(out, initial_state=init_state[0])\n",
        "        out, h1, c1 = self.lstm1(out, initial_state=init_state[1])\n",
        "        out = tf.concat([out, att_out], 2)\n",
        "        out = self.fc(out)\n",
        "        state = [(h0, c0), (h1, c1)]\n",
        "        return out, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3LESBcYP2i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Encoder()\n",
        "decoder_model = Decoder()\n",
        "attention_model = Attention()\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "enc_output, enc_state = encoder_model(encoder_inputs)\n",
        "att_out = attention_model(enc_output)\n",
        "decoder_outputs, _ = decoder_model(decoder_inputs, enc_state, att_out)\n",
        "\n",
        "# общая модель \n",
        "seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "seq2seq.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq6m6kkoP2pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next - in the same way as the Encoder-decoder without attention\n",
        "\n",
        "# P.S.: Encoder-decoder with attention takes longer to learn\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}